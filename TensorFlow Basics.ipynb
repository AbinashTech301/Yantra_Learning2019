{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yantra Learning \n",
    "## TensorFlow Basics\n",
    "### 1. Importing the Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import import_ipynb\n",
    "import tf_utils\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have imported the library, we will walk  through its different applications. We will start with an example, where we compute the loss of one training example. \n",
    "$$loss = \\mathcal{L}(\\hat{y}, y) = (\\hat y^{(i)} - y^{(i)})^2 \\tag{1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to follow the follow the following steps in order to write and run a tensorflow program:\n",
    "\n",
    "1. Create Tensors or variables that are not yet executed/evaluated. \n",
    "2. Define operations between those Tensors.\n",
    "3. Initialize the Tensors. \n",
    "4. Create a Session. \n",
    "5. Run the Session. \n",
    "Therefore, we will create a variable for loss and simply define the loss as a function of some quantities. Then we would use\n",
    "`init=tf.global_variables_initializer()` to initialise and evaluate the loss function.\n",
    "\n",
    "But lets look at one easy example first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mul:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(2)\n",
    "b = tf.constant(10)\n",
    "c = tf.multiply(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, We don't get see 20! We got a tensor saying that the result is a tensor that does not have the shape attribute, and is of type \"int32\". All we did was put in the 'computation graph', but we have not run this computation yet. In order to multiply the two numbers, we need to create a session and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Let's compute the Loss of one training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n"
     ]
    }
   ],
   "source": [
    "y_hat = tf.constant(23, name='y_hat')            # Define y_hat constant and Set it to 23.\n",
    "y = tf.constant(12, name='y')                    # Define y and Set it to 12\n",
    "\n",
    "loss = tf.Variable((y - y_hat)**2, name='loss')  # this creates variable for the loss\n",
    "\n",
    "init = tf.global_variables_initializer()         # When init is run later,we can use (session.run(init)),\n",
    "                                                 # the loss variable will be initialized and ready to be computed\n",
    "with tf.Session() as session:                    # This creates a session and prints the output\n",
    "    session.run(init)                            # This initializes the variables\n",
    "    print(session.run(loss))                     # this prints the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We computed the loss function. So Let's summarize now the steps for a Tensorflow program:\n",
    "1. Create Tensors or variables\n",
    "2. Define Operation between the tensors\n",
    "3. Initialize the tensors \n",
    "4. Create a session \n",
    "5. Finally, Run the session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are two typical ways to create and use sessions in tensorflow: \n",
    "\n",
    "**Method 1:**\n",
    "```python\n",
    "sess = tf.Session()\n",
    "# Run the variables initialization (if needed), run the operations\n",
    "result = sess.run(..., feed_dict = {...})\n",
    "sess.close() # Close the session\n",
    "```\n",
    "**Method 2:**\n",
    "```python\n",
    "with tf.Session() as sess: \n",
    "    # run the variables initialization (if needed), run the operations\n",
    "    result = sess.run(..., feed_dict = {...})\n",
    "    # This takes care of closing the session for you :)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Let's Learn about **Placeholders.**                                                                                      \n",
    "*A placeholder is an object whose value can be specified only later.* To specify values for a placeholder,we can pass in values by using a \"feed dictionary\" (`feed_dict` variable). Below, we created a placeholder for x. This allows us to pass in a number later when we run the session. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.int64, name = 'x')\n",
    "print(sess.run(2 * x, feed_dict = {x: 3}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's learn to compute a Linear Function. \n",
    "We will now write a function to compute $Y = WX + b$, where $W$ and $X$ are random matrices and b is a random vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function():\n",
    "    
    "    \n",
    "    X = tf.constant(np.random.randn(3,1),name=\"X\")\n",
    "    W = tf.constant(np.random.randn(4,3),name=\"W\")\n",
    "    b = tf.constant(np.random.randn(4,1),name=\"b\")\n",
    "    Y = tf.add(tf.matmul(W,X),b)\n",
    "   \n",
    "    # Create and run the session\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    result = sess.run(Y) \n",
    "    \n",
    "    sess.close()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result = [[ 0.33239092]\n",
      " [-1.34709372]\n",
      " [-2.64891946]\n",
      " [-0.20802978]]\n"
     ]
    }
   ],
   "source": [
    "print( \"result = \" + str(linear_function()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning 2\n",
    "Tensorflow offers a variety of commonly used neural network functions like tf.sigmoid and tf.softmax. But we will be using here sigmoid function.\n",
    "More details on Sigmoid function can be found [here](<https://www.python-course.eu/neural_networks_with_python_numpy.php>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Computes the sigmoid of z\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a placeholder for x.\n",
    "    x = tf.placeholder(tf.float32,name='z')\n",
    "\n",
    "    # compute sigmoid(x)\n",
    "    sigmoid = tf.sigmoid(x)\n",
    "\n",
    "    # Create a session, and run it. \n",
    "    # use a feed_dict to pass z's value to x. \n",
    "    with tf.Session() as sess:\n",
    "        # Run session and call the output \"result\"\n",
    "        result = sess.run(sigmoid,feed_dict={x:z})\n",
    "        \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid(0) = 0.5\n",
      "sigmoid(12) = 0.99966466\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoid(0) = \" + str(sigmoid(0)))\n",
    "print (\"sigmoid(12) = \" + str(sigmoid(8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning 3\n",
    "Now,we will create a cost function. We can write our own code or use the built-in fuction. The cost function is defined as\n",
    "$$ J = - \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log a^{ [2] (i)} + (1-y^{(i)})\\log (1-a^{ [2] (i)} )\\large )\\small\\tag{2}$$\n",
    "We will now implement the cross entropy loss. The function we will use is: \n",
    "\n",
    "\n",
    "- `tf.nn.sigmoid_cross_entropy_with_logits(logits = ...,  labels = ...)`\n",
    "\n",
    "\n",
    "$$- \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log \\sigma(z^{[2](i)}) + (1-y^{(i)})\\log (1-\\sigma(z^{[2](i)})\\large )\\small\\tag{2}$$\n",
    "\n",
    "[This Link](<https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits>) provides more information on the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(logits, labels):\n",
    "    \"\"\"\n",
    "    Computes the cost using the sigmoid cross entropy\n",
    "    Arguments:\n",
    "    logits -- vector containing z, output of the last linear unit (before the final sigmoid activation)\n",
    "    labels -- vector of labels y (1 or 0) \n",
    "    \n",
    "    \"z\" corresponds to \"Logits\" and \"y\" corresponds to \"Label\".\n",
    "    \n",
    "    Returns:\n",
    "    cost \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # placeholders for \"logits\" (z) and \"labels\" (y) \n",
    "    z = tf.placeholder(tf.float32,name='logits')\n",
    "    y = tf.placeholder(tf.float32,name='labels')\n",
    "    \n",
    "    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=z,labels=y)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    \n",
    "    cost = sess.run(cost,feed_dict={z:logits,y:labels})\n",
    "    \n",
    "    sess.close()\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = [1.0053872  1.0366408  0.41385433 0.39956617]\n"
     ]
    }
   ],
   "source": [
    "logits = sigmoid(np.array([0.2,0.4,0.7,0.9]))\n",
    "cost = cost(logits, np.array([0,0,1,1]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning 4\n",
    "\n",
    "Most of the times, we have a y vector with numbers ranging from 0 to C-1, where C is the number of classes. Let C = 4, then we might have the following y vector which we will need to convert as follows:\n",
    "\n",
    "\n",
    "<img src=\"images/onehot.png\" style=\"width:600px;height:150px;\">\n",
    "\n",
    "This is called a \"one hot\" encoding, because in the converted representation exactly one element of each column is \"hot\" (meaning set to 1).  In tensorflow, we can use the following fuction: \n",
    "\n",
    "- tf.one_hot(labels, depth, axis) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "    \"\"\"\n",
    "    \n",
    "    C = tf.constant(C,name=\"C\")\n",
    "    \n",
    "    one_hot_matrix = tf.one_hot(labels,C,axis=0)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    \n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    sess.close()\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot = [[0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([1,2,3,0,2,1])\n",
    "one_hot = one_hot_matrix(labels, C = 4)\n",
    "print (\"one_hot = \" + str(one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning 5\n",
    "\n",
    "Now we will initialize a vector of zeros and ones. The function we will use is `tf.ones()`. To initialize with zeros we can use tf.zeros().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ones(shape):\n",
    "    \"\"\"\n",
    "    Creates an array of ones of dimension shape\n",
    "   \n",
    "    \"\"\"\n",
    "\n",
    "    ones = tf.ones(shape)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    \n",
    "    ones = sess.run(ones)\n",
    "    \n",
    "    sess.close()\n",
    "    \n",
    "    return ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ones = [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print (\"ones = \" + str(ones([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
